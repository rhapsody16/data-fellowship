{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c0459e9",
   "metadata": {},
   "source": [
    "# TLC Trips Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b11ab7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6407691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-11 17:20:34--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.160.201.50, 18.160.201.5, 18.160.201.126, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.160.201.50|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 21777258 (21M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘yellow_tripdata_2021-02.parquet.2’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  20.77M  41.2MB/s    in 0.5s    \n",
      "\n",
      "2022-12-11 17:20:34 (41.2 MB/s) - ‘yellow_tripdata_2021-02.parquet.2’ saved [21777258/21777258]\n",
      "\n",
      "--2022-12-11 17:20:35--  https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-02.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.160.201.131, 18.160.201.126, 18.160.201.5, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.160.201.131|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10645466 (10M) [binary/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2021-02.parquet.3’\n",
      "\n",
      "fhv_tripdata_2021-0 100%[===================>]  10.15M  51.6MB/s    in 0.2s    \n",
      "\n",
      "2022-12-11 17:20:35 (51.6 MB/s) - ‘fhv_tripdata_2021-02.parquet.3’ saved [10645466/10645466]\n",
      "\n",
      "--2022-12-11 17:20:35--  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-02.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.160.201.131, 18.160.201.126, 18.160.201.5, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.160.201.131|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 302633211 (289M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘fhvhv_tripdata_2021-02.parquet.1’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 288.61M   147MB/s    in 2.0s    \n",
      "\n",
      "2022-12-11 17:20:37 (147 MB/s) - ‘fhvhv_tripdata_2021-02.parquet.1’ saved [302633211/302633211]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-02.parquet\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d26b4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/12/11 17:20:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/12/11 17:20:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/12/11 17:20:41 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/12/11 17:20:41 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a280baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow = spark.read.parquet(\"yellow_tripdata_2021-02.parquet\")\n",
    "df_fhv = spark.read.parquet(\"fhv_tripdata_2021-02.parquet\")\n",
    "df_fhvhv = spark.read.parquet(\"fhvhv_tripdata_2021-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc4216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2021-02-01 00:40:47|  2021-02-01 00:48:28|            1.0|          2.3|       1.0|                 N|         141|         226|           2|        8.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        12.3|                 2.5|       null|\n",
      "|       1| 2021-02-01 00:07:44|  2021-02-01 00:20:31|            1.0|          1.6|       1.0|                 N|          43|         263|           2|        9.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        13.3|                 0.0|       null|\n",
      "|       1| 2021-02-01 00:59:36|  2021-02-01 01:24:13|            1.0|          5.3|       1.0|                 N|         114|         263|           2|       19.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        22.8|                 2.5|       null|\n",
      "|       2| 2021-02-01 00:03:26|  2021-02-01 00:16:32|            1.0|         2.79|       1.0|                 N|         236|         229|           1|       11.0|  0.5|    0.5|      2.96|         0.0|                  0.3|       17.76|                 2.5|       null|\n",
      "|       2| 2021-02-01 00:20:20|  2021-02-01 00:24:03|            2.0|         0.64|       1.0|                 N|         229|         140|           1|        4.5|  0.5|    0.5|      1.66|         0.0|                  0.3|        9.96|                 2.5|       null|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cab127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00013|2021-02-01 00:01:00|2021-02-01 01:33:00|        null|        null|   null|                B00014|\n",
      "|     B00021         |2021-02-01 00:55:40|2021-02-01 01:06:20|       173.0|        82.0|   null|       B00021         |\n",
      "|     B00021         |2021-02-01 00:14:03|2021-02-01 00:28:37|       173.0|        56.0|   null|       B00021         |\n",
      "|     B00021         |2021-02-01 00:27:48|2021-02-01 00:35:45|        82.0|       129.0|   null|       B00021         |\n",
      "|              B00037|2021-02-01 00:12:50|2021-02-01 00:26:38|        null|       225.0|   null|                B00037|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhv.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7be868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "|hvfhs_license_num|dispatching_base_num|originating_base_num|   request_datetime|  on_scene_datetime|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|trip_miles|trip_time|base_passenger_fare|tolls| bcf|sales_tax|congestion_surcharge|airport_fee|tips|driver_pay|shared_request_flag|shared_match_flag|access_a_ride_flag|wav_request_flag|wav_match_flag|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "|           HV0003|              B02764|              B02764|2021-01-31 23:59:00|2021-02-01 00:10:19|2021-02-01 00:10:40|2021-02-01 00:21:09|          35|          39|      2.06|      629|              17.14|  0.0|0.51|     1.52|                 0.0|       null| 0.0|      9.79|                  N|                N|                  |               N|             N|\n",
      "|           HV0003|              B02764|              B02764|2021-02-01 00:13:35|2021-02-01 00:25:23|2021-02-01 00:27:23|2021-02-01 00:44:01|          39|          35|      3.15|      998|              32.11|  0.0|0.96|     2.85|                 0.0|       null| 0.0|     24.01|                  N|                N|                  |               N|             N|\n",
      "|           HV0005|              B02510|                null|2021-02-01 00:12:55|               null|2021-02-01 00:28:38|2021-02-01 00:38:27|          39|          91|     1.776|      589|              12.67|  0.0|0.38|     1.12|                 0.0|       null| 0.0|      6.91|                  N|                N|                 N|               N|             N|\n",
      "|           HV0005|              B02510|                null|2021-02-01 00:36:01|               null|2021-02-01 00:43:37|2021-02-01 01:23:20|          91|         228|    13.599|     2383|              37.82|  0.0|0.98|     2.91|                 0.0|       null| 7.0|     35.05|                  N|                N|                 N|               N|             N|\n",
      "|           HV0003|              B02872|              B02872|2021-01-31 23:57:50|2021-02-01 00:08:25|2021-02-01 00:08:42|2021-02-01 00:17:57|         126|         250|      2.62|      555|              15.56|  0.0|0.47|     1.38|                 0.0|       null| 0.0|      8.53|                  N|                N|                  |               N|             N|\n",
      "+-----------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+----------+---------+-------------------+-----+----+---------+--------------------+-----------+----+----------+-------------------+-----------------+------------------+----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fhvhv.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a375e197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge',\n",
       " 'airport_fee']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yellow.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65eacb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropOff_datetime',\n",
       " 'PUlocationID',\n",
       " 'DOlocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "500c9648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hvfhs_license_num',\n",
       " 'dispatching_base_num',\n",
       " 'originating_base_num',\n",
       " 'request_datetime',\n",
       " 'on_scene_datetime',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'trip_miles',\n",
       " 'trip_time',\n",
       " 'base_passenger_fare',\n",
       " 'tolls',\n",
       " 'bcf',\n",
       " 'sales_tax',\n",
       " 'congestion_surcharge',\n",
       " 'airport_fee',\n",
       " 'tips',\n",
       " 'driver_pay',\n",
       " 'shared_request_flag',\n",
       " 'shared_match_flag',\n",
       " 'access_a_ride_flag',\n",
       " 'wav_request_flag',\n",
       " 'wav_match_flag']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhvhv.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b28082",
   "metadata": {},
   "source": [
    "### How many taxi trips were there on February 15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b12b0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|total_trip_2021_02|\n",
      "+------------------+\n",
      "|             40322|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_yellow.registerTempTable('df_yellow_table')\n",
    "total_trip_2021_02 = spark.sql(\"\"\" \n",
    "                                SELECT COUNT(tpep_pickup_datetime) AS total_trip_2021_02\n",
    "                                FROM df_yellow_table\n",
    "                                WHERE tpep_pickup_datetime >= '2021-02-15 00:00:00' AND tpep_pickup_datetime < '2021-02-16 00:00:00'\n",
    "                   \n",
    "                   \"\"\")\n",
    "total_trip_2021_02.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6776f1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|total_trip_2021_02|\n",
      "+------------------+\n",
      "|            367170|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fhvhv.registerTempTable('df_fhvhv_table')\n",
    "total_trip_2021_02 = spark.sql(\"\"\" \n",
    "                                SELECT COUNT(pickup_datetime) AS total_trip_2021_02\n",
    "                                FROM df_fhvhv_table\n",
    "                                WHERE pickup_datetime >= '2021-02-15 00:00:00' AND pickup_datetime < '2021-02-16 00:00:00'\n",
    "                   \n",
    "                   \"\"\")\n",
    "total_trip_2021_02.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d9d33e",
   "metadata": {},
   "source": [
    "### Find the longest trip for each day ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f05ee39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:===================================>                  (133 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------------+\n",
      "|pickup_date|longest_distance_trip_by_day|\n",
      "+-----------+----------------------------+\n",
      "| 2021-02-16|                   221188.25|\n",
      "| 2021-02-20|                   188054.03|\n",
      "| 2021-02-08|                   186617.92|\n",
      "| 2021-02-07|                   186510.67|\n",
      "| 2021-02-03|                   186079.73|\n",
      "| 2021-02-17|                   140145.44|\n",
      "| 2021-02-13|                   115928.92|\n",
      "| 2021-02-05|                    91134.16|\n",
      "| 2021-02-26|                    90796.21|\n",
      "| 2021-02-24|                    90073.44|\n",
      "+-----------+----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow = df_yellow.withColumn(\"pickup_date\", df_yellow[\"tpep_pickup_datetime\"].cast('date'))\n",
    "\n",
    "df_yellow.registerTempTable('df_table_yellow')\n",
    "\n",
    "longest_trip_byday_yellow = spark.sql(\"\"\"\n",
    "                     SELECT pickup_date, MAX(trip_distance) as longest_distance_trip_by_day\n",
    "                     FROM df_table_yellow\n",
    "                     WHERE pickup_date >= \"2021-02-01\" AND pickup_date < \"2021-03-01\"\n",
    "                     GROUP BY 1\n",
    "                     ORDER BY longest_distance_trip_by_day DESC\n",
    "                     \"\"\")\n",
    "longest_trip_byday_yellow.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5782a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:===========================================>          (160 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------------+\n",
      "|pickup_date|longest_distance_trip_by_day|\n",
      "+-----------+----------------------------+\n",
      "| 2021-02-18|                      527.11|\n",
      "| 2021-02-10|                       512.5|\n",
      "| 2021-02-09|                      480.73|\n",
      "| 2021-02-27|                      454.49|\n",
      "| 2021-02-22|                      347.41|\n",
      "| 2021-02-20|                      340.64|\n",
      "| 2021-02-19|                      329.16|\n",
      "| 2021-02-17|                      324.19|\n",
      "| 2021-02-16|                     307.661|\n",
      "| 2021-02-24|                      301.73|\n",
      "+-----------+----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fhvhv = df_fhvhv.withColumn(\"pickup_date\", df_fhvhv[\"pickup_datetime\"].cast('date'))\n",
    "\n",
    "df_fhvhv.registerTempTable('df_fhvhv_table')\n",
    "\n",
    "longest_trip_byday_fhvhv = spark.sql(\"\"\"\n",
    "                     SELECT pickup_date, MAX(trip_miles) as longest_distance_trip_by_day\n",
    "                     FROM df_fhvhv_table\n",
    "                     WHERE pickup_date >= \"2021-02-01\" AND pickup_date < \"2021-03-01\"\n",
    "                     GROUP BY 1\n",
    "                     ORDER BY longest_distance_trip_by_day DESC\n",
    "                     \"\"\")\n",
    "longest_trip_byday_fhvhv.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75307bbb",
   "metadata": {},
   "source": [
    "### Find Top 5 Most frequent `dispatching_base_num` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c40e3216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:==================================================>   (188 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|dispatching_base_num|count|\n",
      "+--------------------+-----+\n",
      "|              B00856|35077|\n",
      "|              B01312|33089|\n",
      "|              B01145|31114|\n",
      "|              B02794|30397|\n",
      "|              B03016|29794|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fhv.registerTempTable('df_fhv_table')\n",
    "\n",
    "top5_most_dbm_yellow = spark.sql(\"\"\"\n",
    "                SELECT dispatching_base_num, count(dispatching_base_num) as count\n",
    "                FROM df_fhv_table\n",
    "                GROUP BY 1\n",
    "                ORDER BY 2 DESC\n",
    "                \"\"\")\n",
    "top5_most_dbm_yellow.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f70210cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|dispatching_base_num|  count|\n",
      "+--------------------+-------+\n",
      "|              B02510|3233664|\n",
      "|              B02764| 965568|\n",
      "|              B02872| 882689|\n",
      "|              B02875| 685390|\n",
      "|              B02765| 559768|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top5_most_dbm_fhvhv = spark.sql(\"\"\"\n",
    "                SELECT dispatching_base_num, count(dispatching_base_num) as count\n",
    "                FROM df_fhvhv_table\n",
    "                GROUP BY 1\n",
    "                ORDER BY 2 DESC\n",
    "                \"\"\")\n",
    "                \n",
    "top5_most_dbm_fhvhv.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44117b51",
   "metadata": {},
   "source": [
    "### Find Top 5 Most common location pairs (PUlocationID and DOlocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be9a3fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|PUlocationID|Count_DOlocationID|\n",
      "+------------+------------------+\n",
      "|         236|             74898|\n",
      "|         237|             72887|\n",
      "|         141|             46222|\n",
      "|         239|             45036|\n",
      "|         186|             44295|\n",
      "+------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top5_most_PUlocationID_yellow = spark.sql(\"\"\" \n",
    "                         SELECT PUlocationID, COUNT(PUlocationID) as Count_DOlocationID\n",
    "                         FROM df_yellow_table\n",
    "                         GROUP BY 1\n",
    "                         ORDER BY 2 DESC\n",
    "                         \"\"\")\n",
    "\n",
    "top5_most_PUlocationID_yellow.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b64e4a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|PUlocationID|Count_DOlocationID|\n",
      "+------------+------------------+\n",
      "|          61|            203777|\n",
      "|          76|            166959|\n",
      "|          37|            140636|\n",
      "|          79|            137901|\n",
      "|          42|            137246|\n",
      "+------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top5_most_PUlocationID_fhvhv = spark.sql(\"\"\" \n",
    "                         SELECT PUlocationID, COUNT(PUlocationID) as Count_DOlocationID\n",
    "                         FROM df_fhvhv_table\n",
    "                         GROUP BY 1\n",
    "                         ORDER BY 2 DESC\n",
    "                         \"\"\")\n",
    "\n",
    "top5_most_PUlocationID_fhvhv.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9d14d409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|DOlocationID|Count_DOlocationID|\n",
      "+------------+------------------+\n",
      "|         236|             73310|\n",
      "|         237|             61979|\n",
      "|         141|             44436|\n",
      "|         239|             42309|\n",
      "|         238|             41055|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top5_most_DOlocationID_yellow = spark.sql(\"\"\" \n",
    "                         SELECT DOlocationID, COUNT(DOlocationID) as Count_DOlocationID\n",
    "                         FROM df_yellow_table\n",
    "                         GROUP BY 1\n",
    "                         ORDER BY 2 DESC\n",
    "                         \"\"\")\n",
    "\n",
    "top5_most_DOlocationID_yellow.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81fccfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|DOlocationID|Count_DOlocationID|\n",
      "+------------+------------------+\n",
      "|         265|            357369|\n",
      "|          61|            202250|\n",
      "|          76|            168094|\n",
      "|          37|            140826|\n",
      "|          42|            127432|\n",
      "+------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top5_most_DOlocationID_fhvhv = spark.sql(\"\"\" \n",
    "                         SELECT DOlocationID, COUNT(DOlocationID) as Count_DOlocationID\n",
    "                         FROM df_fhvhv_table\n",
    "                         GROUP BY 1\n",
    "                         ORDER BY 2 DESC\n",
    "                         \"\"\")\n",
    "\n",
    "top5_most_DOlocationID_fhvhv.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
